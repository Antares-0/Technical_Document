# 大模型部署

## 一、部署方案
1. 涉及组件：Dify+Ollama+Xinference+(Qwen+Deepseek)+(Embedding+Rerank)


## 二、企业级大模型应用场景（现在大模型通常在企业的哪些场景中使用）
1. 基于RAG场景
   - 背景：为什么会出现RAG场景的相关开发？
     - 大模型的知识冻结：大模型无法获得训练之后的新数据
     - 大模型的幻觉问题：回答不够准确，瞎说
   - 流程：
     1. 文件解析：从文本中提取出有用的信息
     2. 文件切割：将文本切分成chunk
     3. 向量化：使用**嵌入模型**，将文本转变为对应的向量
     4. 知识入库：将知识存储到向量数据库中存储起来，涉及到索引的建立和数据的存储
     5. query提问：外部用户发起问题，这里会使用到**嵌入模型**将用户的提问转换成模型可识别的向量
     6. 知识检索：从向量数据库中检索出最相似的数据
     7. 知识重排序：使用**重排序模型**将数据按照一定顺序排序并准备发送给大模型
     8. 增强：将排序后的知识融合到prompt中
     9. 生成：调用**对话大模型**回答增强后的问题
   - 全流程共四处使用到大模型：
     1. 向量化阶段，使用嵌入模型针对输入进行处理
     2. query提问阶段，使用嵌入模型针对输入进行处理
     3. 知识重排序阶段，使用重排序模型将数据按照一定顺序排列
     4. 生成阶段，调用对话大模型回答问题
2. 基于Agent场景
   - 背景：充分利用LLM的推理决策能力，通过增加规划、记忆和工具调用的能力，构造一个能够独立思考、逐步完成给定目标的智能体
   - Agent架构：LLM（大模型）、Planning（规划决策）、Action（动作）、工具（Tools）、记忆（Memory）
     - LLM大模型：大模型作为大脑，提供推理、规划和知识理解能力，是AI Agent的决策中枢
     - Memory记忆：存储单次对话周期的上限文信息，属于临时信息存储机制（受限于模型的上下文窗口长度）
       - 长期记忆定义：可以横跨多个任务或者时间周期，可存储并调用核心知识，非即时任务
       - 长期记忆实现：可以通过模型参数微调（固化知识）、知识图谱（结构化语义网络）或向量数据库（相似性检索）方式实现
     - Tools工具使用：调用外部工具扩展能力边界
     - Planning规划决策：通过任务分解、反思与自省框架实现复杂任务处理。例如使用思维链将目标拆解
     - Action动作：实际执行决策的模块，涵盖软件接口操作和物理交互

## 三、









参考资料：
1. 尚硅谷视频讲解：https://www.bilibili.com/video/BV1EJvPzUELq
2. 