# 机器学习概览

## 一、机器学习、深度学习
1. 机器学习的概念是使用一系列模型去模拟真实世界；这个模型没有限制，可以是KNN、可以是神经网络、可以是其他各种模型
2. 深度学习是机器学习的一个子类别，深度学习使用的模型是确定的，都是深度神经网络模型；也就是说，深度学习是指定模型为深度神经网络的一种特殊的机器学习

## 二、机器学习术语
1. 数据集：数据集分为训练集、验证集、测试集
   1. 训练集：用于训练模型的数据
   2. 验证集：用于调节超参数的数据
   3. 测试集：用于评估模型性能的数据
2. 参数
   1. 参数：模型通过训练得到的值，也就是模型学习的对象
   2. 超参数：用户设置的值，不能通过训练自动学习；比如学习率，正则化系数等；可以理解为预设参数
3. 数据
   1. 样本：数据集中的一条记录，关于一个事物的描述（张三的年龄、血压、血脂，是否有心脏病）
   2. 特征：数据集中一系列反映事件或对象在某方面的表现或性质的事项，称为特征或属性（年龄、血压、血脂）
   3. 特征向量：将样本的所有特征标识为向量的形式，输入到模型中（张三、李四、王五等人每个人都构成一个向量）

## 三、机器学习基本理论
1. 机器学习三要素：模型、策略、算法
   1. 模型：总结数据的内在规律，使用哪种数学描述真实世界？（例如：线性函数、二次函数...）
   2. 策略：选择最优模型的评价准则（怎样判断一个模型是好还是坏？）
   3. 算法：选取最优模型的具体方法（怎样逐步获得最好的模型？）
2. 拓展：开发程序一样类似于机器学习三要素
   1. 模型：就是你开发出来的程序，也就是你对世界、业务的建模是什么样的？（对业务的抽象，比如电商系统）
   2. 策略：怎样评价你的开发程序好不好？DAU？点击率？（对抽象的评价，怎么评价电商系统，有哪些指标）
   3. 算法：怎么样持续优化系统，提高策略对应的指标呢？（提高抽象策略的路径，怎么提高这些指标？）
3. 机器学习分类（按照是否有监督）
   1. 有监督学习：提供数据和结果进行机器学习的过程（有监督学习获得的是对当前输入的直接正确答案，明确知道在优化什么，而且反馈及时容易区分“正确行为”）
   2. 无监督学习：提供数据不提供结果进行机器学习的过程（无监督学习是对当前输入进行无目标的规律挖掘，不知道在优化什么）
   3. 半监督学习：提供数据，结果不定提供进行机器学习的过程
   4. 强化学习：通过与环境交互，改进行为的学习过程（强化学习有明确的优化目标，但是反馈不及时且不容易区分“正确行为”）
   ```txt
   有监督学习与无监督学习的区别主要在于，是否知道自己在优化什么，在发掘哪方面的数据规律
   有监督学习：知道自己在学习的是，怎么判断一个人是否有疾病
   无监督学习：不知道自己的在学习什么
   
   有监督学习与强化学习的区别主要在于，反馈是否及时且有明确的好坏标准？
   强化学习：反馈是延迟的，而且评价通常不明确；例如下棋中最后一步才知道奖励是正的，这不代表本次比赛没有任何失误
   有监督学习：反馈是及时的，评价通常明确；例如判断一个人是不是患有疾病，数据输入后立即获知
   
   无监督学习与强化学习的区别主要在于，是否有明确的优化目标，知不知道在发掘什么规律？
   强化学习：明确优化目标就是最大reward
   无监督学习：不清楚在挖掘什么数据规律
   ```
4. 无监督学习主要是通过学习分析数据特征，如果新输入具有这种特征，那就可以认为包含这种规律并给予正向反馈
5. 监督学习主要分为分类和回归，离散情况下使用分类；连续情况下使用回归
6. 机器学习方法分类：
   
    ![机器学习方法分类](./fig/机器学习方法分类.png)
7. 机器学习过程
   1. 收集数据
   2. 数据清洗
   3. <font color='yellow'>特征工程：对数据的格式进行转换，确保数据适合用于机器学习</font>
   4. <font color='red'>选择算法：选择合适的算法（根据场景、数据量和数据特点进行选择）</font>
   5. <font color='green'>模型训练：使用训练数据对模型参数进行调整</font>
   6. <font color='purple'>模型评估：使用测试数据集对模型性能进行评估</font>
   7. 模型优化：提升模型效果
   8. 模型部署：将训练好的模型部署到生产环境中

## <font color='yellow'>四、特征工程</font>
1. 特征工程（Feature Engineering）：指的是通过对原始数据的处理、转换和构造，生成新的特征或选择有效的特征，从而提高模型的性能。简单来说，特征工程是将原始数据转换为可以更好地表示问题的特征形式，帮助模型更好地理解和学习数据中的规律。
2. 特征选择：特征太多，选择一部分特征；不改变也不创新，加速模型训练过程
   1. 方差评估法：计算某一个特征的方差，波动越大，代表特征越重要
   2. 随机干扰法：对不同特征分别加一个随机干扰项，如果某个特征加完干扰后模型效果显著变差，说明特征重要
   3. ...
3. 特征转换：将特征转换为另一种指标
   1. 归一化操作：将特征转换到某一个固定的区间范围内。适用于对尺度敏感的模型（KNN、SVM）
   2. 标准化操作：减去平均值除以标准差，标准化操作后的数据会被缩放为均值为0、标准差为1的分布
   3. 对数化操作：对于数量级变化比较大的数据，对数化操作非常合适
   4. 类别编码操作：
      1. 独热编码（One-hot Encoding）：将类别型变量转换为二进制列（男、女）
      2. 标签编码（Label Encoding）：将类别型变量转换为整数（红球0、绿球1、白球2，模型会认为红色和白色的距离更大，引入误导）
      3. 目标编码（Target Encoding）：用平均值代替变量
      4. 频率编码（Frequency Encoding）：按照出现的次数进行编码（红球5个=5，白球2个=2）
4. 特征构造：从无到有，构造出新的特征，基于已有的特征获取
5. 特征降维：与特征选择不同，是基于目前数据，提取出新的特征并实现降维效果
   1. 主成分分析PCA
   2. 线性判别分析LDA
   3. ...
6. 特征工程实战，真实算法中常用的特征工程方案
   1. 低方差过滤法：方差值小于某一阈值就过滤掉 
   ```python
   # 引入sklearn
   from sklearn.feature_selection import VarianceThreshold
   # 过滤掉方差小于0.9的
   vt = VarianceThreshold(0.9)
   X_filtered = vt.fit_transform(X)
   # 打印
   print(X_filtered)
   ```
   2. 相关系数法：通过计算特征与目标变量或特征之间的相关性，筛选出高相关性特征（与目标相关）或剔除冗余特征（特征间高度相关）
      1. 皮尔逊相关系数：线性相关性评估
         ```python
         import pandas as pd
         # 计算X和y之间的皮尔逊相关系数
         print(X.corrwith(y, method="pearson"))
         ```
      2. 斯皮尔曼相关系数：非线形相关性评估或者数据分布不符合正态分布的情况
         ```python
         import pandas as pd
         print(X.corrwith(y, method="spearman"))
         ```
   3. 主成分分析（PCA）：通过线形变换将高维数据投影到低维空间，同时保留数据的主要变化模式（找到一个n-1维平面，使得当前n维在这个平面上投影对应的loss最小）
   ```python
   import numpy as np
   from sklearn.decomposition import PCA
   from sklearn.preprocessing import StandardScaler
   
   # 构造数据
   n_samples = 1000
   ## 第1个主成分方向
   component1 = np.random.normal(0, 1, n_samples)
   ## 第2个主成分方向
   component2 = np.random.normal(0, 0.2, n_samples)
   ## 第3个方向（噪声，方差较小）
   noise = np.random.normal(0, 0.1, n_samples)
   ## 构造3维数据
   X = np.vstack([component1 - component2, component1 + component2, component2 + noise]).T
   
   # 标准化
   scaler = StandardScaler()
   X_standardized = scaler.fit_transform(X)
   
   # 应用PCA，将3维数据降维到2维
   pca = PCA(n_components=2)
   X_pca = pca.fit_transform(X_standardized)
   ```

## <font color='red'>五、模型选择和模型评估</font>
1. 损失函数：用于描述模型预测误差的大小；本质是模型参数的函数；要求非负。
2. 常见损失函数
   1. 0-1损失函数：命中即无损失，loss = 0；不命中即存在损失，loss = 1
   2. 平方损失函数：真实值与预测值的平方差（L1范数的平方）
   3. 绝对损失函数：真实值与预测值的绝对值（L1范数）
   4. 对数似然损失函数：适用于预测函数是概率的场景。【P(图片是猫) = 0.9 && P(图片是狗) = 0.1】
3. 训练误差与泛化误差
   1. 训练误差：模型在训练数据集上的平均误差，也叫经验误差
   2. 泛化误差：测试数据集上的平均误差（泛化：应用在其他场景下的适应能力）
4. 一般情况下对模型评估的策略，就是考察经验误差；当经验风险最小时，就认为取到了最优的模型。这种策略被称为经验风险最小化（empirical risk minimization，ERM）
5. 欠拟合和过拟合
   1. 拟合：是指机器学习模型在训练数据上学习到规律并生成预测结果的过程
   2. 欠拟合：是指模型在训练数据上表现不佳，无法很好地捕捉数据中的规律（学的不好，考得也不好）
   3. 过拟合：是指模型在训练数据上表现得很好，但在测试数据或新数据上表现较差的情况（学的好，考试不会）
   4. 欠拟合和过拟合的根本原因和解决办法
      1. 欠拟合
         1. 产生原因
            1. 模型复杂度不足：模型过于简单，无法捕捉数据中的复杂关系。
            2. 特征不足：输入特征不充分，或者特征选择不恰当，导致模型无法充分学习数据的模式。
            3. 训练不充分：训练过程中迭代次数太少，模型没有足够的时间学习数据的规律。
            4. 过强的正则化：正则化项设置过大，强制模型过于简单，导致模型无法充分拟合数据。
         2. 解决方案
            1. 选择更复杂的模型
            2. 增加特征或者改进特征工程
            3. 增加训练时间和轮数
            4. 减少正则化强度
      2. 过拟合
         1. 产生原因
            1. 模型复杂度过高：模型过于复杂，参数太多。
            2. 训练数据不足：数据集太小，模型能记住训练数据的细节，但无法泛化到新数据。
            3. 特征过多：特征太多，模型可能会“记住”数据中的噪声，而不是学到真正的规律。
            4. 训练过长：训练时间过长，导致模型学习到训练数据中的噪声，而非数据的真正规律。
         2. 解决办法
            1. 减少模型复杂度：降低模型的参数数量、使用简化的模型或降维来减小模型复杂度。
            2. 增加训练数据：收集更多数据，或通过数据增强来增加训练数据的多样性。
            3. 使用正则化：引入L1、L2正则化，避免过度拟合训练数据。
            4. 交叉验证：使用交叉验证技术评估模型在不同数据集上的表现，以减少过拟合的风险。
            5. 早停：训练时，当模型的验证损失不再下降时，提前停止训练，避免过度拟合训练集。
6. 正则化：是一种在训练机器学习模型时，在损失函数中添加额外项，来惩罚过大的参数，进而限制模型复杂度、避免过拟合，提高模型泛化能力的技术
   1. 基础思想：机器学习的过程是对参数进行学习的过程，正则化会惩罚过大、过多的参数；参数越大、参数数量越多，正则化惩罚越严重
      
   $Loss = \frac{1}{n} \left( \sum_{i=1}^n (f(\boldsymbol{x}_i) - y_i)^2 + \lambda \sum_{i=1}^k \omega_i^2 \right)$

   2. 



## <font color='green'>六、模型求解算法</font>




## <font color='purple'>七、模型评估</font>


参考资料：
1. 尚硅谷机器学习视频：https://www.bilibili.com/video/BV1BYe4z5E9z