# 大模型技术之RAG

## 一、什么是RAG
1. RAG就是通过检索获取相关的知识并将其融入Prompt，让大模型能够参考相应的知识从而给出合理回答。因此，可以将RAG的核心理解为“检索+生成”，
   - 前者主要是利用向量数据库的高效存储和检索能力，召回目标知识
   - 后者则是利用大模型和Prompt工程，将召回的知识合理利用，生成目标答案
2. RAG完整流程
   - 数据准备阶段：主要是将私域数据向量化后构建索引并存入数据库的过程
     - 数据提取
       - 数据加载：从不同源头获得多种数据格式的数据，依赖数据自身的情况统一处理为一种格式
       - 数据处理：数据过滤、压缩、格式化等
       - 元数据提取：提取数据中的关键信息
     - 文本分割：文本分割需要考虑两个条件，语义和Tokens的长度限制，普遍来说有以下两种分割方式
       - 固定长度分割：根据embedding模型的token长度限制，将文本分割为固定长度，会损失掉大部分的语义信息；可以通过句分割 + 冗余信息来缓解
       - 句分割：按照句子切分，常见的切分符号包括：感叹号、问号、换行符等
     - 向量化embedding：向量化是一个将文本数据转换为向量矩阵的过程，该过程会直接影响到后续检索的效果
       - 常见的向量化模型如下：
       - 对于一些罕见的专有名词，可以使用上述的模型进行微调来实现
     - 数据入库
   - 应用阶段：用户提问 -- 数据召回 -- 注入prompt -- LLM生成答案
3. RAG的必要性
   1. 大模型不具备某一方面的专业能力，RAG作为一种外界的知识库对LLM的能力进行了提升
   2. 数据安全性考量：某些企业不愿意将数据传给第三方平台进行训练
   3. 幻觉问题：大模型具有幻觉，经常会胡说八道，大模型需要某一方面的系统性知识


## 二、RAG的具体使用





参考文档
1. 快速入门RAG整体流程：https://blog.csdn.net/m0_59164304
2. 